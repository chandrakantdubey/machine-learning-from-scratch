ML pre-requisites(maths) : Linear Algebra, Probability Theory, Calculus, Optimization Theory(optional), Information theory(optional)

Linear Algebra: Lecture course by Gilbert Strang

Probability theory: MIT 6.041 (it contains parts of Bayesian inference as well)

Calculus: your high school and college classes are enough 

Once basic maths is done then we move to ML.

Classical ML : CS229. Either by Andrew NG or someone else. Follow their lecture notes and solve their problem sets.

Reference books for classical ML that I followed: PRML by Christopher bishop, Pattern Classification by Duda, Hart and Stork 

After getting comfortable with classical ML we move to Deep Learning and everything else.

Deep Learning and Computer Vision: CS231n. Very good lecture and assignments 

Reference book: Deep Learning by Ian Goodfellow. This is the best book on deep learning. I’ve read some chapters of it many many times. Beautiful maths and intuitions 

MLOps: dvc, WandB, MLFlow

NLP: I just read hugging face blogs. I haven’t spent much time with classical NLP though.

Alignment/AI safety/AI explainability: Anthropic Blogs(I’m a noob in this, just started learning couple months ago)

Additionally:

Blogs: Lilian Weng(OpenAI)’s blogs, colah’s blogs 

Additionally: arxiv. I read many papers from arxiv 

Karas and Tensorflow blogs: for introductory code about modern deep learning frameworks 

Competitions: Kaggle

Cloud compute. GCP/collab/Kaggle notebooks
